# Methods 

All code is available at github.com/dib-lab/2021-panmers (results section 1; DOI: 10.5281/zenodo.6761161), github.com/dib-lab/2021-orpheum-sim (results section 2;  DOI: 10.5281/zenodo.6761169), and https://github.com/dib-lab/2021-metapangenome-example (results section 3; DOI: 10.5281/zenodo.6761180).

### Selection of benchmarking species for pangenome analysis
We selected a species representative for each of the 23 phyla in GTDB rs202 [@doi:10.1093/nar/gkab776]. 
To select representative species, we first removed species with fewer than 20 genomes and greater than 1000 genomes.
While this approach scales beyond 1000 genomes, we elected to benchmark smaller sets to iterate over the potential parameter space more quickly.
Of species remaining after filtering, we selected the species within each phyla that had the largest number of genomes.
We downloaded these genomes from GenBank.
Species names are recorded in **Figure @fig:tree_fig**.

### Calculating the gene-based pangenome with roary 
To calculate the gene-based pangenome, we first annotated each genome using prokka [@doi:10.1093/bioinformatics/btu153].
We then used the resulting GFF annotations files to calculate the pangenome with roary using default settings [@doi:10.1093/bioinformatics/btv421].

### Calculating the k-mer based pangenome with sourmash 
To calculate k-mer based pangenomes, we used sourmash `sketch` to generate signatures from the prokka-predicted amino acid sequences (`.faa` files) [@doi:10.21105/joss.00027]. 
We used the protein alphabet (*k* = 7, 8, 9, 10, 11), dayhoff alphabet (*k* = 13, 15, 17), and the hydrophobic-polar alphabet (*k* = 27, 31). 
All signatures were calculated with a scaled value of 100.
The scaled parameter controls the fraction of the total k-mers represented by the sketch; a scaled value of 100 indicates that 1/100th of the distinct k-mers in a genome were included in each sketch.
We converted signatures from json format into a genome x hash presence-absence matrix.

### Correlating gene-based and k-mer based pangenomes 
Using the presence-absence matrices for the gene-based and k-mer-based pangenomes, we correlated total genes/k-mers observed per genome and total unique genes/k-mers observed per genome for each species.
We used the `rowSums()` function in R to determine the number of genes/unique genes per matrix, then used the `lm()` function with default parameters to correlate the values.
We also used the Mantel test to determine whether genomes that were most similar in the gene presence-absence matrix were also most similar in the k-mer presence-absence matrix [@pmid:6018555]. 
We used the `mantel()` function in the R vegan package to perform this test [@doi:10.1111/j.1654-1103.2003.tb02228.x]. 
We used distance matrices calculated with the `dist()` function using the parameter `method = "binary"` as input to the mantel test.

To estimate the containment between the sequences in core genomes as estimated by roary and as estimated by k~aa~-mers, we limited the core genome to sequences present in all genomes. 
We then generated FracMinHash protein sketches using sourmash `sketch` (*k*=10, scaled=100) for roary core sequences and k~aa~-mer core sequences and estimated containment using sourmash `compare` [@doi:10.21105/joss.00027]. 

### Generating standard pangenome metrics with pagoo 
The pagoo R package provides functions to analyze bacterial pangenomes [@doi:10.1016/j.crmeth.2021.100085].
We used this package to generate standard pangenome metrics and visualizations.
These metrics are based on the presence-absence matrices generated above and include calculation of the core, shell, and cloud genome sizes and estimation of the alpha value in Heaps law for estimation of pangenome openness.

### Augmenting benchmarking species set to include genomes not in GTDB for open reading frame prediction
We next generated a benchmarking data set for open reading frame prediction. 
We selected a genome from each of the 23 species evaluated above, choosing the GTDB rs202 representative genome for each species.
Genome accessions are recorded in **Table @tbl:gtdb_acc**.
Given that open reading frame prediction relies on a database, and we used k-mers in GTDB rs202 to generate this database, we also wanted to select genomes that were not in GTDB to evaluate this method.
We determined the bacterial and archaeal genomes that were added to RefSeq after the construction of GTDB rs202 (April 2021-November 2021).
From this set, we selected a representative genome from each of the distinct NCBI phyla represented among these genomes, 20 in total.
Genome accessions are recorded in **Table @tbl:refseq_acc**.
We then ran GTDB-tk on these genomes to predict the GTDB taxonomy of each [@doi:10.1093/bioinformatics/btz848].

### Simulating coding domain sequence and non coding domain sequence reads with polyester
We next created a labelled data set of simulated reads that were generated from either coding domain sequences (CDS) or non-coding regions within each genome.
We annotated the genomes with bakta to produce CDS ranges [@doi:10.1099/mgen.0.000685], and used polyester to simulate reads from CDS or non-coding regions [@doi:10.1093/bioinformatics/btv272]. 
We used the default short read error profile within polyester.

### Determining short read open reading frames with orpheum 
We used the orpheum tool to predict open reading frames from simulated short reads [@doi:10.1101/2021.07.09.450799].
Orpheum was developed to predict open reading frames in short RNA-seq reads from Eukaryotic organisms without a reference genome or transcriptome sequence [@doi:10.1101/2021.07.09.450799].
Orpheum performs six-frame translation on nucleotide sequencing reads, calculates k-mers in an amino acid encoding at the designated k-mer length, and then estimates the containment of k-mers in a reference database in each translated frame. 
It then selects all open reading frames based on a containment threshold, and returns those reads as translated amino acid sequences.
Open reading frames are excluded if they contain stop codons, low complexity sequences, or if the read is too short to perform translation.
Reads are designated as non-coding if they don't reach the containment threshold and are not excluded for other reasons.
We constructed a database from all genomes in GTDB rs202.
We either downloaded predicted open reading frames from GenBank, or generated them using prodigal [@doi:10.1186/1471-2105-11-119], and translated them into protein sequences using transeq [@url:http://ebi.ac.uk/Tools/emboss/transeq/index.html].
We then used to build a nodegraph using a k~aa~-mer size of 10.

### K~aa~-mer metapangenome analysis of iHMP metagenomes
We used sourmash, spacegraphcats, and orpheum to perform k~aa~-mer metapangenome analysis of 12 iHMP time series gut microbiomes captured by short read shotgun metagenomes [@doi:10.1038/s41586-019-1237-9].
We downloaded samples HSM6XRQB, HSM6XRQI, HSM6XRQK, HSM6XRQM, HSM6XRQO, HSM67VF9, HSM67VFD, HSM67VFJ, HSM7CYY7, HSM7CYYD, HSM7CYY9, HSM7CYYB from ibdmdb.org.
We adapter and quality trimmed each sample with fastp (parameters `--detect_adapter_for_pe`, `--qualified_quality_phred 4`, `--length_required 31`, and `--correction`) [@doi:10.1093/bioinformatics/bty560], removed human host sequencing reads with bbduk (parameters `k=31`, reference file https://drive.google.com/file/d/0B3llHR93L14wd0pSSnFULUlhcUk/edit?usp=sharing), and k-mer trimmed reads using khmer `trim-low-abund.py` (parameters `-C 3`, `-Z 18`, `-V`) [@doi:10.12688/f1000research.6924.1].
We then used sourmash `gather` to infer the taxonomic profile of each sample, using the GTDB rs202 database (*k* = 31, https://osf.io/w4bcm/) [@doi:10.1038/s41586-019-1237-9].
We summarized the results to species-level using the GTDB taxonomy.
We retained species with a cumulative sum of at least 2% (sum of `f_unique_to_query`) across metagenome reads as query genomes.
We downloaded each genome from GenBank (**Table @tbl:acc**) and performed spacegraphcats assembly graph queries with each (parameters `ksize: 31`, `radius: 1`, `paired_reads: true`) [@doi:10.1186/s13059-020-02066-4].
Using the returned reads, we predicted open reading frames using orpheum `translate` (parameters `--jaccard-threshold 0.39`, `--alphabet protein`, `--peptide-ksize 10`) and using species-level GTDB databases.
We sketched each set of translated reads using sourmash `sketch` (parameters `protein`, `-p k=10,scaled=100,protein`) [@doi:10.21105/joss.00027], converted each sketch to a csv file, and then combined csv files for a single query species across all metagenomes. 
This long format csv was used as input for the R pangenome package pagoo, using the `pagoo()` function [@doi:10.1016/j.crmeth.2021.100085].
We used pagoo methods `pg$gg_binmap()`, `pg$summary_stats()`, and `pg$pg_power_law_fit()` to visualize the pangenome, calculate the size of the core, shell, and cloud, and estimate alpha. 

| species | accession |
|:-------:|:-----------:|
| *Parabacteroides distasonis* | GCA_000162535.1 |
| *Enterocloster bolteae* | GCF_003433765.1 |
| *Bacteroides fragilis*   | GCF_003458955.1 |
| *Parabacteroides merdae* | GCF_003475305.1 |
| *Bacteroides uniformis*  | GCF_009020325.1 |
| *Phocaeicola vulgatus*   | GCF_009025805.1 |
Table: Query genome GTDB species names and GenBank accessions.
{#tbl:acc}

## Comparing k~aa~-mer, *de novo*, and reference (meta)pangenomes

We compared the k~aa~-mer metapangenomes against other (meta)pangenomes. 
We first constructed a reference pangenome for each query species as detailed in the methods section, "Calculated the gene-based pangenome with roary."
We used all genomes in the GTDB rs202 database for a given species (**Table @tbl:acc**).
We then constructed *de novo* metapangenomes for each species.
Using quality controlled reads from each sample, we assembled each metagenome separately using megahit with default parameters [@doi:10.1093/bioinformatics/btv033].
We binned the resultant assemblies using metabat2 with parameter `-m 1500` [@doi:10.7717/peerj.7359].
We assigned GTDB species to each bin using sourmash `gather` (DNA, *k* = 31, scaled = 2000) against the GTDB rs202 database, selecting the species of the best match [@doi:10.1101/2022.01.11.475838].
We decontaminated each bin with charcoal using default parameters [@url:https://github.com/dib-lab/charcoal].
We annotated each bin using prokka [@doi:10.1093/bioinformatics/btu153].
To compare the sequence content of the (meta)pangenomes, we sketched the protein sequences from the *de novo* and reference (meta)pangenomes using sourmash `sketch` (protein, *k* = 10, scaled = 100).
We intersected the hashes in these sketches to assess shared sequencing content, and visualized it using the R complexUpset package [@doi:10.5281/zenodo.3700590].

To further compare the sequence content of the k~aa~-mer metapangenomes to the *de novo* and reference (meta)pangenomes, we mapped the reads used to build the k~aa~-mer metapangenomes iteratively against the (meta)pangenomes.
We first mapped the reads against the reference pangenome using bwa `mem` with default parameters [@url:https://arxiv.org/abs/1303.3997].
We used samtools `stat` to determine read mapping statistics, and samtools `view` and `fastq` to extract the unmapped reads [@doi:10.1093/bioinformatics/btp352].
We then mapped the unmapped reads against the *de novo* metapangenome. 
To prepare the *de novo* metapangenome for mapping, we clustered nucleotide sequences at 95% using cd-hit-est [@doi:10.1093/bioinformatics/btl158].
We then mapped the unmapped reads using bwa `mem` with default parameters.
We extracted unmapped reads using the same procedure as above.
To determine whether more reads mapped in amino acid space, we translated the reference and *de novo* (meta)pangenomes into protein sequences using transeq [@url:http://ebi.ac.uk/Tools/emboss/transeq/index.html], and then repeated the same iterative mapping procedure using paladin `align` [@doi:10.1093/bioinformatics/btx021].
To test whether the fraction of mapped reads increased between the two mapping protocols, we used the R function `t.test()` using parameter `paired = TRUE`.
